{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMTKVJs/9X4qthnb/OD156F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mafloan/TelecomChallengeAllura/blob/main/TelecomMorosos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva secci√≥n"
      ],
      "metadata": {
        "id": "4zS2y4upPslj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6a72976",
        "outputId": "547c4119-1e5c-4ed2-d529-ff74a7987f69"
      },
      "source": [
        "!pip install pandas matplotlib requests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee6db586",
        "outputId": "1077728c-c65c-433a-a403-ca5d4160d310"
      },
      "source": [
        "# Either run the command below or the one after it, but not both.\n",
        "!python telecomx_pipeline.py --from raw\n",
        "# Or local:\n",
        "# !python telecomx_pipeline.py --from local --path ./TelecomX_Data.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/telecomx_pipeline.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "# Configuraci√≥n de rutas\n",
        "OUTPUT_DIR = \"reports\"\n",
        "CSV_PATH = \"outputs/telecomx_clean.csv\"\n",
        "MD_PATH = os.path.join(OUTPUT_DIR, \"EDA_TelecomX.md\")\n",
        "PDF_PATH = os.path.join(OUTPUT_DIR, \"EDA_TelecomX.pdf\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# 1. Cargar dataset\n",
        "try:\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(\"No se encontr√≥ el archivo limpio en outputs/. Corre primero telecomx_pipeline.py\")\n",
        "\n",
        "# 2. Resumen de datos\n",
        "n_rows, n_cols = df.shape\n",
        "summary = df.info()\n",
        "nulos = df.isnull().sum().to_dict()\n",
        "\n",
        "# 3. Distribuci√≥n de churn\n",
        "if \"churn\" in df.columns:\n",
        "    churn_counts = df[\"churn\"].value_counts()\n",
        "    plt.figure()\n",
        "    churn_counts.plot(kind=\"bar\")\n",
        "    plt.title(\"Distribuci√≥n de Churn\")\n",
        "    plt.ylabel(\"Cantidad\")\n",
        "    churn_img = os.path.join(OUTPUT_DIR, \"churn_dist.png\")\n",
        "    plt.savefig(churn_img)\n",
        "    plt.close()\n",
        "else:\n",
        "    churn_counts = None\n",
        "    churn_img = None\n",
        "\n",
        "# 4. Variables categ√≥ricas top\n",
        "cat_plots = []\n",
        "for col in df.select_dtypes(include=[\"object\"]).columns[:3]:\n",
        "    plt.figure()\n",
        "    df[col].value_counts().head(5).plot(kind=\"bar\")\n",
        "    plt.title(f\"Top categor√≠as en {col}\")\n",
        "    img_path = os.path.join(OUTPUT_DIR, f\"cat_{col}.png\")\n",
        "    plt.savefig(img_path)\n",
        "    plt.close()\n",
        "    cat_plots.append(img_path)\n",
        "\n",
        "# 5. Variables num√©ricas\n",
        "num_plots = []\n",
        "for col in df.select_dtypes(include=[\"int64\", \"float64\"]).columns[:2]:\n",
        "    plt.figure()\n",
        "    df[col].hist(bins=30)\n",
        "    plt.title(f\"Distribuci√≥n de {col}\")\n",
        "    img_path = os.path.join(OUTPUT_DIR, f\"num_{col}.png\")\n",
        "    plt.savefig(img_path)\n",
        "    plt.close()\n",
        "    num_plots.append(img_path)\n",
        "\n",
        "# 6. Guardar Markdown\n",
        "with open(MD_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"# Informe EDA - TelecomX\\n\\n\")\n",
        "    f.write(f\"Filas: {n_rows}, Columnas: {n_cols}\\n\\n\")\n",
        "    f.write(\"## Valores nulos por columna\\n\")\n",
        "    for k, v in nulos.items():\n",
        "        f.write(f\"- {k}: {v}\\n\")\n",
        "    if churn_counts is not None:\n",
        "        f.write(\"\\n## Distribuci√≥n de Churn\\n\")\n",
        "        f.write(str(churn_counts.to_dict()))\n",
        "\n",
        "# 7. Guardar PDF\n",
        "styles = getSampleStyleSheet()\n",
        "elements = []\n",
        "doc = SimpleDocTemplate(PDF_PATH, pagesize=A4)\n",
        "elements.append(Paragraph(\"<b>Informe EDA - TelecomX</b>\", styles['Title']))\n",
        "elements.append(Spacer(1, 12))\n",
        "elements.append(Paragraph(f\"Filas: {n_rows}, Columnas: {n_cols}\", styles['Normal']))\n",
        "\n",
        "# Nulos\n",
        "elements.append(Paragraph(\"<b>Valores nulos por columna:</b>\", styles['Heading2']))\n",
        "for k, v in nulos.items():\n",
        "    elements.append(Paragraph(f\"{k}: {v}\", styles['Normal']))\n",
        "\n",
        "# Im√°genes\n",
        "def add_image(path, width=400):\n",
        "    if path and os.path.exists(path):\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Image(path, width, width*0.6))\n",
        "\n",
        "if churn_img:\n",
        "    add_image(churn_img)\n",
        "for img in cat_plots + num_plots:\n",
        "    add_image(img)\n",
        "\n",
        "doc.build(elements)\n",
        "\n",
        "print(f\"‚úÖ Reportes generados: {MD_PATH} y {PDF_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "igtjOmM3Sc-O",
        "outputId": "22cbb5fc-1ce9-4a78-b44b-50ec30629299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No se encontr√≥ el archivo limpio en outputs/. Corre primero telecomx_pipeline.py",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1451241464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/telecomx_clean.csv'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1451241464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No se encontr√≥ el archivo limpio en outputs/. Corre primero telecomx_pipeline.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# 2. Resumen de datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No se encontr√≥ el archivo limpio en outputs/. Corre primero telecomx_pipeline.py"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d89de41b",
        "outputId": "59a0e7dd-e59a-4587-8bc3-3ed9fe69cbf3"
      },
      "source": [
        "!pip install reportlab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "üîπ 1. Visualizar la matriz de correlaci√≥n\n",
        "\n",
        "Sirve para ver c√≥mo se relacionan las variables num√©ricas entre s√≠ y, sobre todo, con la variable objetivo (Churn o Cancelaci√≥n).\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Correlaci√≥n solo con variables num√©ricas\n",
        "corr = df.corr(numeric_only=True)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Matriz de Correlaci√≥n\", fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Relaci√≥n de cada variable con la variable objetivo\n",
        "correlacion_churn = corr[\"Churn\"].sort_values(ascending=False)\n",
        "print(\"Correlaci√≥n con la variable Churn:\")\n",
        "print(correlacion_churn)\n",
        "\n",
        "\n",
        "üëâ Aqu√≠ te interesa detectar variables con correlaciones m√°s altas (positivas o negativas) con Churn.\n",
        "Ejemplo:\n",
        "\n",
        "tenure con correlaci√≥n negativa (clientes antiguos cancelan menos).\n",
        "\n",
        "MonthlyCharges positiva (cuotas altas ‚Üí m√°s cancelaciones).\n",
        "\n",
        "üîπ 2. Importancia de variables seg√∫n modelo\n",
        "üìå Regresi√≥n Log√≠stica\n",
        "\n",
        "Los coeficientes (model.coef_) indican el peso de cada variable.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Coeficiente\": model_log.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Coeficiente\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "\n",
        "print(coef)\n",
        "\n",
        "üìå KNN\n",
        "\n",
        "KNN no da importancia directa de variables, pero pod√©s:\n",
        "\n",
        "Normalizar datos para que todas tengan el mismo peso.\n",
        "\n",
        "Usar permutation importance (de sklearn.inspection):\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "result = permutation_importance(model_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "importances = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": result.importances_mean\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "print(importances)\n",
        "\n",
        "üìå Random Forest\n",
        "\n",
        "Muy usado para ranking de variables üöÄ\n",
        "\n",
        "importances = model_rf.feature_importances_\n",
        "forest_importance = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": importances\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "print(forest_importance)\n",
        "\n",
        "# Visualizaci√≥n\n",
        "sns.barplot(x=\"Importancia\", y=\"Variable\", data=forest_importance)\n",
        "plt.title(\"Importancia de Variables - Random Forest\")\n",
        "plt.show()\n",
        "\n",
        "üìå SVM\n",
        "\n",
        "Para kernel lineal (SVC(kernel=\"linear\")), pod√©s ver coeficientes:\n",
        "\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Coeficiente\": model_svm.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Coeficiente\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "\n",
        "print(coef)\n",
        "\n",
        "\n",
        "Si us√°s kernel no lineal (RBF, poly), mejor aplicar permutation importance igual que con KNN.\n",
        "\n",
        "‚úÖ Con esto, vas a tener:\n",
        "\n",
        "Matriz de correlaci√≥n inicial ‚Üí exploraci√≥n.\n",
        "\n",
        "Ranking de variables por modelo ‚Üí explicaci√≥n y conclusiones.\n",
        "\n",
        "¬øQuer√©s que te prepare un bloque de c√≥digo integrado que corra todos estos an√°lisis (correlaci√≥n + importancia en cada modelo) y te devuelva tablas y gr√°ficos listos para tu reporte?\n",
        "\n",
        "You said:\n",
        "ranking de variables por modelo\n",
        "ChatGPT said:\n",
        "\n",
        "¬°Excelente! üôå Entonces vamos directo a lo que ped√≠s: c√≥mo obtener el ranking de variables por cada modelo.\n",
        "\n",
        "Te paso un bloque de c√≥digo que pod√©s correr despu√©s de entrenar tus modelos (model_log, model_knn, model_rf, model_svm).\n",
        "\n",
        "üìå C√≥digo para ranking de variables por modelo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Diccionario donde iremos guardando los rankings\n",
        "rankings = {}\n",
        "\n",
        "# =============== 1. REGRESI√ìN LOG√çSTICA ===============\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_log.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Importancia\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "rankings[\"Log√≠stica\"] = coef[[\"Variable\", \"Importancia_Abs\"]]\n",
        "\n",
        "\n",
        "# =============== 2. KNN (Permutation Importance) ===============\n",
        "result_knn = permutation_importance(model_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "imp_knn = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": result_knn.importances_mean\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"KNN\"] = imp_knn\n",
        "\n",
        "\n",
        "# =============== 3. RANDOM FOREST ===============\n",
        "imp_rf = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_rf.feature_importances_\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"Random Forest\"] = imp_rf\n",
        "\n",
        "\n",
        "# =============== 4. SVM ===============\n",
        "if hasattr(model_svm, \"coef_\"):  # si es kernel lineal\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": np.abs(model_svm.coef_[0])\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "else:  # si es kernel no lineal ‚Üí usar permutation importance\n",
        "    result_svm = permutation_importance(model_svm, X_test, y_test, n_repeats=10, random_state=42)\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": result_svm.importances_mean\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "rankings[\"SVM\"] = imp_svm\n",
        "\n",
        "\n",
        "# =============== VISUALIZACI√ìN GENERAL ===============\n",
        "for modelo, df_rank in rankings.items():\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.barplot(x=\"Importancia\", y=\"Variable\", data=df_rank.head(10))\n",
        "    plt.title(f\"Top 10 Variables - {modelo}\")\n",
        "    plt.show()\n",
        "\n",
        "üìä Qu√© vas a obtener\n",
        "\n",
        "Una tabla con el ranking de variables para cada modelo.\n",
        "\n",
        "Gr√°ficos de barras con el Top 10 de las variables m√°s relevantes.\n",
        "\n",
        "üëâ Pregunta clave:\n",
        "¬øQuer√©s que lo armemos para que al final te d√© un ranking consolidado (comparando qu√© variables aparecen m√°s veces en el top de cada modelo), o prefer√≠s ver cada ranking modelo por modelo por separado?\n",
        "\n",
        "You said:\n",
        "s√≠\n",
        "ChatGPT said:\n",
        "\n",
        "¬°Genial! üôå Entonces te armo la versi√≥n que genera:\n",
        "\n",
        "Ranking por modelo (como antes).\n",
        "\n",
        "Ranking consolidado ‚Üí combinando los resultados de todos los modelos para ver qu√© variables son consistentes.\n",
        "\n",
        "üìå C√≥digo con ranking consolidado\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Diccionario donde iremos guardando los rankings\n",
        "rankings = {}\n",
        "\n",
        "# =============== 1. REGRESI√ìN LOG√çSTICA ===============\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_log.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Importancia\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "rankings[\"Log√≠stica\"] = coef[[\"Variable\", \"Importancia_Abs\"]].rename(columns={\"Importancia_Abs\":\"Importancia\"})\n",
        "\n",
        "\n",
        "# =============== 2. KNN (Permutation Importance) ===============\n",
        "result_knn = permutation_importance(model_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "imp_knn = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": result_knn.importances_mean\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"KNN\"] = imp_knn\n",
        "\n",
        "\n",
        "# =============== 3. RANDOM FOREST ===============\n",
        "imp_rf = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_rf.feature_importances_\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"Random Forest\"] = imp_rf\n",
        "\n",
        "\n",
        "# =============== 4. SVM ===============\n",
        "if hasattr(model_svm, \"coef_\"):  # kernel lineal\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": np.abs(model_svm.coef_[0])\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "else:  # kernel no lineal ‚Üí permutation importance\n",
        "    result_svm = permutation_importance(model_svm, X_test, y_test, n_repeats=10, random_state=42)\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": result_svm.importances_mean\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "rankings[\"SVM\"] = imp_svm\n",
        "\n",
        "\n",
        "# =============== VISUALIZACI√ìN INDIVIDUAL ===============\n",
        "for modelo, df_rank in rankings.items():\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.barplot(x=\"Importancia\", y=\"Variable\", data=df_rank.head(10))\n",
        "    plt.title(f\"Top 10 Variables - {modelo}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =============== RANKING CONSOLIDADO ===============\n",
        "# Normalizamos cada ranking (escala 0-1 para poder comparar)\n",
        "consolidado = []\n",
        "for modelo, df_rank in rankings.items():\n",
        "    df_norm = df_rank.copy()\n",
        "    df_norm[\"Importancia\"] = df_norm[\"Importancia\"] / df_norm[\"Importancia\"].max()\n",
        "    df_norm[\"Modelo\"] = modelo\n",
        "    consolidado.append(df_norm)\n",
        "\n",
        "consolidado = pd.concat(consolidado)\n",
        "\n",
        "# Promedio de importancia por variable\n",
        "ranking_final = consolidado.groupby(\"Variable\")[\"Importancia\"].mean().sort_values(ascending=False).reset_index()\n",
        "\n",
        "print(\"üîù Ranking Consolidado de Variables:\")\n",
        "print(ranking_final.head(15))\n",
        "\n",
        "# Visualizaci√≥n consolidada\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=\"Importancia\", y=\"Variable\", data=ranking_final.head(10))\n",
        "plt.title(\"Top 10 Variables - Ranking Consolidado\")\n",
        "plt.show()\n",
        "\n",
        "üìä Qu√© vas a obtener:\n",
        "\n",
        "Ranking y gr√°fico por cada modelo (Log√≠stica, KNN, RF, SVM).\n",
        "\n",
        "Ranking consolidado ‚Üí una tabla con el promedio normalizado de importancia de cada variable, mostrando cu√°les son las m√°s relevantes de manera consistente."
      ],
      "metadata": {
        "id": "lOp3m8G_Wgx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Voy a suponer un dataset t√≠pico de churn de telecomunicaciones (como el de Telco Customer Churn de Kaggle). Obviamente, cuando vos corras el c√≥digo con tus datos, las variables y el orden exacto pueden variar.\n",
        "\n",
        "üìä Ejemplo de interpretaci√≥n\n",
        "\n",
        "Supongamos que el ranking consolidado devuelve este Top 10:\n",
        "\n",
        "Variable\tImportancia Promedio\n",
        "Tenure\t0.92\n",
        "MonthlyCharges\t0.88\n",
        "Contract_TwoYear\t0.75\n",
        "InternetService\t0.72\n",
        "PaymentMethod\t0.69\n",
        "TechSupport\t0.65\n",
        "OnlineSecurity\t0.63\n",
        "Dependents\t0.59\n",
        "SeniorCitizen\t0.54\n",
        "StreamingTV\t0.51\n",
        "üîé Interpretaci√≥n\n",
        "\n",
        "Tenure (Antig√ºedad del cliente)\n",
        "\n",
        "Alta importancia en todos los modelos.\n",
        "\n",
        "Correlaci√≥n negativa con churn ‚Üí los clientes m√°s antiguos tienden a permanecer, mientras que los nuevos cancelan m√°s.\n",
        "\n",
        "MonthlyCharges (Cuota mensual)\n",
        "\n",
        "Fuerte correlaci√≥n positiva con churn.\n",
        "\n",
        "Los clientes con cargos mensuales m√°s altos son m√°s propensos a cancelar, posiblemente por percepci√≥n de costo excesivo.\n",
        "\n",
        "Contract (Tipo de contrato)\n",
        "\n",
        "Contratos de dos a√±os reducen la cancelaci√≥n dr√°sticamente (seguridad de permanencia).\n",
        "\n",
        "Contratos mensuales tienen mayor riesgo de churn.\n",
        "\n",
        "InternetService (Tipo de servicio de internet)\n",
        "\n",
        "Clientes con fibra √≥ptica presentan m√°s cancelaciones en comparaci√≥n con DSL o sin internet, posiblemente por problemas de costo/soporte.\n",
        "\n",
        "PaymentMethod (M√©todo de pago)\n",
        "\n",
        "Pagos electr√≥nicos autom√°ticos suelen asociarse con menor churn.\n",
        "\n",
        "Pagos manuales con tarjeta/cheque ‚Üí mayor churn.\n",
        "\n",
        "TechSupport y OnlineSecurity\n",
        "\n",
        "Los clientes que cuentan con soporte t√©cnico o seguridad online presentan menos cancelaciones.\n",
        "\n",
        "Indican que servicios de valor agregado fidelizan.\n",
        "\n",
        "Dependents (Dependientes en el hogar)\n",
        "\n",
        "Hogares con dependientes cancelan menos (quiz√°s por uso compartido del servicio).\n",
        "\n",
        "SeniorCitizen (Adultos mayores)\n",
        "\n",
        "Se observa un poco m√°s de churn en clientes mayores, aunque no es tan fuerte como otras variables.\n",
        "\n",
        "StreamingTV / StreamingMovies\n",
        "\n",
        "Moderada importancia ‚Üí clientes que usan streaming pueden estar m√°s comprometidos, pero tambi√©n sensibles a fallas o precio.\n",
        "\n",
        "‚úÖ Conclusi√≥n para el negocio\n",
        "\n",
        "Factores protectores contra el churn: contratos largos, servicios adicionales (soporte t√©cnico, seguridad online), m√©todo de pago autom√°tico, antig√ºedad del cliente.\n",
        "\n",
        "Factores de riesgo: altas tarifas mensuales, contratos mensuales, clientes nuevos, uso de fibra √≥ptica sin soporte adecuado.\n",
        "\n",
        "Esto le da a la empresa palancas de acci√≥n:\n",
        "\n",
        "Incentivar contratos m√°s largos.\n",
        "\n",
        "Ofrecer descuentos o beneficios a clientes con altas cuotas mensuales.\n",
        "\n",
        "Mejorar soporte t√©cnico y servicios extra.\n",
        "\n",
        "Dise√±ar campa√±as espec√≠ficas para clientes nuevos (primeros 6 meses son cr√≠ticos)."
      ],
      "metadata": {
        "id": "yecSmEO8W09F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "üìå C√≥digo completo con reporte autom√°tico\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# ====================================\n",
        "# 1. Ranking por modelo\n",
        "# ====================================\n",
        "rankings = {}\n",
        "\n",
        "# --- Regresi√≥n Log√≠stica ---\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_log.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Importancia\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "rankings[\"Log√≠stica\"] = coef[[\"Variable\", \"Importancia_Abs\"]].rename(columns={\"Importancia_Abs\":\"Importancia\"})\n",
        "\n",
        "# --- KNN (Permutation Importance) ---\n",
        "result_knn = permutation_importance(model_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "imp_knn = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": result_knn.importances_mean\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"KNN\"] = imp_knn\n",
        "\n",
        "# --- Random Forest ---\n",
        "imp_rf = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_rf.feature_importances_\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"Random Forest\"] = imp_rf\n",
        "\n",
        "# --- SVM ---\n",
        "if hasattr(model_svm, \"coef_\"):  # kernel lineal\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": np.abs(model_svm.coef_[0])\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "else:  # kernel no lineal\n",
        "    result_svm = permutation_importance(model_svm, X_test, y_test, n_repeats=10, random_state=42)\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": result_svm.importances_mean\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "rankings[\"SVM\"] = imp_svm\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 2. Ranking consolidado\n",
        "# ====================================\n",
        "consolidado = []\n",
        "for modelo, df_rank in rankings.items():\n",
        "    df_norm = df_rank.copy()\n",
        "    df_norm[\"Importancia\"] = df_norm[\"Importancia\"] / df_norm[\"Importancia\"].max()\n",
        "    df_norm[\"Modelo\"] = modelo\n",
        "    consolidado.append(df_norm)\n",
        "\n",
        "consolidado = pd.concat(consolidado)\n",
        "\n",
        "ranking_final = consolidado.groupby(\"Variable\")[\"Importancia\"].mean().sort_values(ascending=False).reset_index()\n",
        "\n",
        "print(\"üîù Ranking Consolidado de Variables:\")\n",
        "print(ranking_final.head(15))\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 3. Visualizaci√≥n consolidada\n",
        "# ====================================\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=\"Importancia\", y=\"Variable\", data=ranking_final.head(10))\n",
        "plt.title(\"Top 10 Variables - Ranking Consolidado\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 4. Mini-reporte autom√°tico\n",
        "# ====================================\n",
        "top_vars = ranking_final.head(10)[\"Variable\"].tolist()\n",
        "\n",
        "print(\"\\nüìã Reporte Autom√°tico de Interpretaci√≥n:\\n\")\n",
        "\n",
        "for var in top_vars:\n",
        "    if \"tenure\" in var.lower():\n",
        "        print(f\"- {var}: La antig√ºedad del cliente es clave. Clientes con m√°s tiempo suelen cancelar menos.\")\n",
        "    elif \"monthly\" in var.lower() or \"charge\" in var.lower():\n",
        "        print(f\"- {var}: Los cargos mensuales altos incrementan la probabilidad de cancelaci√≥n.\")\n",
        "    elif \"contract\" in var.lower():\n",
        "        print(f\"- {var}: El tipo de contrato influye: contratos largos reducen la cancelaci√≥n, los mensuales aumentan el riesgo.\")\n",
        "    elif \"payment\" in var.lower():\n",
        "        print(f\"- {var}: El m√©todo de pago es relevante. Pagos autom√°ticos suelen asociarse con menos churn.\")\n",
        "    elif \"internet\" in var.lower():\n",
        "        print(f\"- {var}: El tipo de servicio de internet impacta. Fibra √≥ptica suele tener m√°s cancelaci√≥n que DSL.\")\n",
        "    elif \"support\" in var.lower() or \"security\" in var.lower():\n",
        "        print(f\"- {var}: Servicios adicionales como soporte t√©cnico o seguridad online reducen el churn.\")\n",
        "    elif \"senior\" in var.lower():\n",
        "        print(f\"- {var}: Los clientes mayores tienden a cancelar un poco m√°s que otros segmentos.\")\n",
        "    elif \"depend\" in var.lower():\n",
        "        print(f\"- {var}: Los clientes con dependientes en el hogar suelen permanecer m√°s tiempo.\")\n",
        "    elif \"stream\" in var.lower():\n",
        "        print(f\"- {var}: El uso de streaming puede fidelizar, pero tambi√©n aumenta la sensibilidad a precio y calidad.\")\n",
        "    else:\n",
        "        print(f\"- {var}: Variable relevante detectada, merece un an√°lisis m√°s detallado en el negocio.\")\n",
        "\n",
        "üìä Qu√© hace este c√≥digo\n",
        "\n",
        "Genera ranking de importancia por cada modelo.\n",
        "\n",
        "Construye un ranking consolidado (promedio normalizado entre modelos).\n",
        "\n",
        "Muestra un gr√°fico del Top 10 consolidado.\n",
        "\n",
        "Produce un mini-reporte interpretado autom√°ticamente, con explicaciones sobre las variables m√°s importantes (tenure, charges, contract, etc.)."
      ],
      "metadata": {
        "id": "BleRPSOrW2oX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}