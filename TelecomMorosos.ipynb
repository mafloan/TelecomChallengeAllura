{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMTKVJs/9X4qthnb/OD156F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mafloan/TelecomChallengeAllura/blob/main/TelecomMorosos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ],
      "metadata": {
        "id": "4zS2y4upPslj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6a72976",
        "outputId": "547c4119-1e5c-4ed2-d529-ff74a7987f69"
      },
      "source": [
        "!pip install pandas matplotlib requests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee6db586",
        "outputId": "1077728c-c65c-433a-a403-ca5d4160d310"
      },
      "source": [
        "# Either run the command below or the one after it, but not both.\n",
        "!python telecomx_pipeline.py --from raw\n",
        "# Or local:\n",
        "# !python telecomx_pipeline.py --from local --path ./TelecomX_Data.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/telecomx_pipeline.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "# Configuración de rutas\n",
        "OUTPUT_DIR = \"reports\"\n",
        "CSV_PATH = \"outputs/telecomx_clean.csv\"\n",
        "MD_PATH = os.path.join(OUTPUT_DIR, \"EDA_TelecomX.md\")\n",
        "PDF_PATH = os.path.join(OUTPUT_DIR, \"EDA_TelecomX.pdf\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# 1. Cargar dataset\n",
        "try:\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(\"No se encontró el archivo limpio en outputs/. Corre primero telecomx_pipeline.py\")\n",
        "\n",
        "# 2. Resumen de datos\n",
        "n_rows, n_cols = df.shape\n",
        "summary = df.info()\n",
        "nulos = df.isnull().sum().to_dict()\n",
        "\n",
        "# 3. Distribución de churn\n",
        "if \"churn\" in df.columns:\n",
        "    churn_counts = df[\"churn\"].value_counts()\n",
        "    plt.figure()\n",
        "    churn_counts.plot(kind=\"bar\")\n",
        "    plt.title(\"Distribución de Churn\")\n",
        "    plt.ylabel(\"Cantidad\")\n",
        "    churn_img = os.path.join(OUTPUT_DIR, \"churn_dist.png\")\n",
        "    plt.savefig(churn_img)\n",
        "    plt.close()\n",
        "else:\n",
        "    churn_counts = None\n",
        "    churn_img = None\n",
        "\n",
        "# 4. Variables categóricas top\n",
        "cat_plots = []\n",
        "for col in df.select_dtypes(include=[\"object\"]).columns[:3]:\n",
        "    plt.figure()\n",
        "    df[col].value_counts().head(5).plot(kind=\"bar\")\n",
        "    plt.title(f\"Top categorías en {col}\")\n",
        "    img_path = os.path.join(OUTPUT_DIR, f\"cat_{col}.png\")\n",
        "    plt.savefig(img_path)\n",
        "    plt.close()\n",
        "    cat_plots.append(img_path)\n",
        "\n",
        "# 5. Variables numéricas\n",
        "num_plots = []\n",
        "for col in df.select_dtypes(include=[\"int64\", \"float64\"]).columns[:2]:\n",
        "    plt.figure()\n",
        "    df[col].hist(bins=30)\n",
        "    plt.title(f\"Distribución de {col}\")\n",
        "    img_path = os.path.join(OUTPUT_DIR, f\"num_{col}.png\")\n",
        "    plt.savefig(img_path)\n",
        "    plt.close()\n",
        "    num_plots.append(img_path)\n",
        "\n",
        "# 6. Guardar Markdown\n",
        "with open(MD_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"# Informe EDA - TelecomX\\n\\n\")\n",
        "    f.write(f\"Filas: {n_rows}, Columnas: {n_cols}\\n\\n\")\n",
        "    f.write(\"## Valores nulos por columna\\n\")\n",
        "    for k, v in nulos.items():\n",
        "        f.write(f\"- {k}: {v}\\n\")\n",
        "    if churn_counts is not None:\n",
        "        f.write(\"\\n## Distribución de Churn\\n\")\n",
        "        f.write(str(churn_counts.to_dict()))\n",
        "\n",
        "# 7. Guardar PDF\n",
        "styles = getSampleStyleSheet()\n",
        "elements = []\n",
        "doc = SimpleDocTemplate(PDF_PATH, pagesize=A4)\n",
        "elements.append(Paragraph(\"<b>Informe EDA - TelecomX</b>\", styles['Title']))\n",
        "elements.append(Spacer(1, 12))\n",
        "elements.append(Paragraph(f\"Filas: {n_rows}, Columnas: {n_cols}\", styles['Normal']))\n",
        "\n",
        "# Nulos\n",
        "elements.append(Paragraph(\"<b>Valores nulos por columna:</b>\", styles['Heading2']))\n",
        "for k, v in nulos.items():\n",
        "    elements.append(Paragraph(f\"{k}: {v}\", styles['Normal']))\n",
        "\n",
        "# Imágenes\n",
        "def add_image(path, width=400):\n",
        "    if path and os.path.exists(path):\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Image(path, width, width*0.6))\n",
        "\n",
        "if churn_img:\n",
        "    add_image(churn_img)\n",
        "for img in cat_plots + num_plots:\n",
        "    add_image(img)\n",
        "\n",
        "doc.build(elements)\n",
        "\n",
        "print(f\"✅ Reportes generados: {MD_PATH} y {PDF_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "igtjOmM3Sc-O",
        "outputId": "22cbb5fc-1ce9-4a78-b44b-50ec30629299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No se encontró el archivo limpio en outputs/. Corre primero telecomx_pipeline.py",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1451241464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/telecomx_clean.csv'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1451241464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No se encontró el archivo limpio en outputs/. Corre primero telecomx_pipeline.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# 2. Resumen de datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No se encontró el archivo limpio en outputs/. Corre primero telecomx_pipeline.py"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d89de41b",
        "outputId": "59a0e7dd-e59a-4587-8bc3-3ed9fe69cbf3"
      },
      "source": [
        "!pip install reportlab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "🔹 1. Visualizar la matriz de correlación\n",
        "\n",
        "Sirve para ver cómo se relacionan las variables numéricas entre sí y, sobre todo, con la variable objetivo (Churn o Cancelación).\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Correlación solo con variables numéricas\n",
        "corr = df.corr(numeric_only=True)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Matriz de Correlación\", fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Relación de cada variable con la variable objetivo\n",
        "correlacion_churn = corr[\"Churn\"].sort_values(ascending=False)\n",
        "print(\"Correlación con la variable Churn:\")\n",
        "print(correlacion_churn)\n",
        "\n",
        "\n",
        "👉 Aquí te interesa detectar variables con correlaciones más altas (positivas o negativas) con Churn.\n",
        "Ejemplo:\n",
        "\n",
        "tenure con correlación negativa (clientes antiguos cancelan menos).\n",
        "\n",
        "MonthlyCharges positiva (cuotas altas → más cancelaciones).\n",
        "\n",
        "🔹 2. Importancia de variables según modelo\n",
        "📌 Regresión Logística\n",
        "\n",
        "Los coeficientes (model.coef_) indican el peso de cada variable.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Coeficiente\": model_log.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Coeficiente\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "\n",
        "print(coef)\n",
        "\n",
        "📌 KNN\n",
        "\n",
        "KNN no da importancia directa de variables, pero podés:\n",
        "\n",
        "Normalizar datos para que todas tengan el mismo peso.\n",
        "\n",
        "Usar permutation importance (de sklearn.inspection):\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "result = permutation_importance(model_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "importances = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": result.importances_mean\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "print(importances)\n",
        "\n",
        "📌 Random Forest\n",
        "\n",
        "Muy usado para ranking de variables 🚀\n",
        "\n",
        "importances = model_rf.feature_importances_\n",
        "forest_importance = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": importances\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "print(forest_importance)\n",
        "\n",
        "# Visualización\n",
        "sns.barplot(x=\"Importancia\", y=\"Variable\", data=forest_importance)\n",
        "plt.title(\"Importancia de Variables - Random Forest\")\n",
        "plt.show()\n",
        "\n",
        "📌 SVM\n",
        "\n",
        "Para kernel lineal (SVC(kernel=\"linear\")), podés ver coeficientes:\n",
        "\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Coeficiente\": model_svm.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Coeficiente\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "\n",
        "print(coef)\n",
        "\n",
        "\n",
        "Si usás kernel no lineal (RBF, poly), mejor aplicar permutation importance igual que con KNN.\n",
        "\n",
        "✅ Con esto, vas a tener:\n",
        "\n",
        "Matriz de correlación inicial → exploración.\n",
        "\n",
        "Ranking de variables por modelo → explicación y conclusiones.\n",
        "\n",
        "¿Querés que te prepare un bloque de código integrado que corra todos estos análisis (correlación + importancia en cada modelo) y te devuelva tablas y gráficos listos para tu reporte?\n",
        "\n",
        "You said:\n",
        "ranking de variables por modelo\n",
        "ChatGPT said:\n",
        "\n",
        "¡Excelente! 🙌 Entonces vamos directo a lo que pedís: cómo obtener el ranking de variables por cada modelo.\n",
        "\n",
        "Te paso un bloque de código que podés correr después de entrenar tus modelos (model_log, model_knn, model_rf, model_svm).\n",
        "\n",
        "📌 Código para ranking de variables por modelo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Diccionario donde iremos guardando los rankings\n",
        "rankings = {}\n",
        "\n",
        "# =============== 1. REGRESIÓN LOGÍSTICA ===============\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_log.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Importancia\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "rankings[\"Logística\"] = coef[[\"Variable\", \"Importancia_Abs\"]]\n",
        "\n",
        "\n",
        "# =============== 2. KNN (Permutation Importance) ===============\n",
        "result_knn = permutation_importance(model_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "imp_knn = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": result_knn.importances_mean\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"KNN\"] = imp_knn\n",
        "\n",
        "\n",
        "# =============== 3. RANDOM FOREST ===============\n",
        "imp_rf = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_rf.feature_importances_\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"Random Forest\"] = imp_rf\n",
        "\n",
        "\n",
        "# =============== 4. SVM ===============\n",
        "if hasattr(model_svm, \"coef_\"):  # si es kernel lineal\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": np.abs(model_svm.coef_[0])\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "else:  # si es kernel no lineal → usar permutation importance\n",
        "    result_svm = permutation_importance(model_svm, X_test, y_test, n_repeats=10, random_state=42)\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": result_svm.importances_mean\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "rankings[\"SVM\"] = imp_svm\n",
        "\n",
        "\n",
        "# =============== VISUALIZACIÓN GENERAL ===============\n",
        "for modelo, df_rank in rankings.items():\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.barplot(x=\"Importancia\", y=\"Variable\", data=df_rank.head(10))\n",
        "    plt.title(f\"Top 10 Variables - {modelo}\")\n",
        "    plt.show()\n",
        "\n",
        "📊 Qué vas a obtener\n",
        "\n",
        "Una tabla con el ranking de variables para cada modelo.\n",
        "\n",
        "Gráficos de barras con el Top 10 de las variables más relevantes.\n",
        "\n",
        "👉 Pregunta clave:\n",
        "¿Querés que lo armemos para que al final te dé un ranking consolidado (comparando qué variables aparecen más veces en el top de cada modelo), o preferís ver cada ranking modelo por modelo por separado?\n",
        "\n",
        "You said:\n",
        "sí\n",
        "ChatGPT said:\n",
        "\n",
        "¡Genial! 🙌 Entonces te armo la versión que genera:\n",
        "\n",
        "Ranking por modelo (como antes).\n",
        "\n",
        "Ranking consolidado → combinando los resultados de todos los modelos para ver qué variables son consistentes.\n",
        "\n",
        "📌 Código con ranking consolidado\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Diccionario donde iremos guardando los rankings\n",
        "rankings = {}\n",
        "\n",
        "# =============== 1. REGRESIÓN LOGÍSTICA ===============\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_log.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Importancia\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "rankings[\"Logística\"] = coef[[\"Variable\", \"Importancia_Abs\"]].rename(columns={\"Importancia_Abs\":\"Importancia\"})\n",
        "\n",
        "\n",
        "# =============== 2. KNN (Permutation Importance) ===============\n",
        "result_knn = permutation_importance(model_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "imp_knn = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": result_knn.importances_mean\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"KNN\"] = imp_knn\n",
        "\n",
        "\n",
        "# =============== 3. RANDOM FOREST ===============\n",
        "imp_rf = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_rf.feature_importances_\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"Random Forest\"] = imp_rf\n",
        "\n",
        "\n",
        "# =============== 4. SVM ===============\n",
        "if hasattr(model_svm, \"coef_\"):  # kernel lineal\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": np.abs(model_svm.coef_[0])\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "else:  # kernel no lineal → permutation importance\n",
        "    result_svm = permutation_importance(model_svm, X_test, y_test, n_repeats=10, random_state=42)\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": result_svm.importances_mean\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "rankings[\"SVM\"] = imp_svm\n",
        "\n",
        "\n",
        "# =============== VISUALIZACIÓN INDIVIDUAL ===============\n",
        "for modelo, df_rank in rankings.items():\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.barplot(x=\"Importancia\", y=\"Variable\", data=df_rank.head(10))\n",
        "    plt.title(f\"Top 10 Variables - {modelo}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =============== RANKING CONSOLIDADO ===============\n",
        "# Normalizamos cada ranking (escala 0-1 para poder comparar)\n",
        "consolidado = []\n",
        "for modelo, df_rank in rankings.items():\n",
        "    df_norm = df_rank.copy()\n",
        "    df_norm[\"Importancia\"] = df_norm[\"Importancia\"] / df_norm[\"Importancia\"].max()\n",
        "    df_norm[\"Modelo\"] = modelo\n",
        "    consolidado.append(df_norm)\n",
        "\n",
        "consolidado = pd.concat(consolidado)\n",
        "\n",
        "# Promedio de importancia por variable\n",
        "ranking_final = consolidado.groupby(\"Variable\")[\"Importancia\"].mean().sort_values(ascending=False).reset_index()\n",
        "\n",
        "print(\"🔝 Ranking Consolidado de Variables:\")\n",
        "print(ranking_final.head(15))\n",
        "\n",
        "# Visualización consolidada\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=\"Importancia\", y=\"Variable\", data=ranking_final.head(10))\n",
        "plt.title(\"Top 10 Variables - Ranking Consolidado\")\n",
        "plt.show()\n",
        "\n",
        "📊 Qué vas a obtener:\n",
        "\n",
        "Ranking y gráfico por cada modelo (Logística, KNN, RF, SVM).\n",
        "\n",
        "Ranking consolidado → una tabla con el promedio normalizado de importancia de cada variable, mostrando cuáles son las más relevantes de manera consistente."
      ],
      "metadata": {
        "id": "lOp3m8G_Wgx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Voy a suponer un dataset típico de churn de telecomunicaciones (como el de Telco Customer Churn de Kaggle). Obviamente, cuando vos corras el código con tus datos, las variables y el orden exacto pueden variar.\n",
        "\n",
        "📊 Ejemplo de interpretación\n",
        "\n",
        "Supongamos que el ranking consolidado devuelve este Top 10:\n",
        "\n",
        "Variable\tImportancia Promedio\n",
        "Tenure\t0.92\n",
        "MonthlyCharges\t0.88\n",
        "Contract_TwoYear\t0.75\n",
        "InternetService\t0.72\n",
        "PaymentMethod\t0.69\n",
        "TechSupport\t0.65\n",
        "OnlineSecurity\t0.63\n",
        "Dependents\t0.59\n",
        "SeniorCitizen\t0.54\n",
        "StreamingTV\t0.51\n",
        "🔎 Interpretación\n",
        "\n",
        "Tenure (Antigüedad del cliente)\n",
        "\n",
        "Alta importancia en todos los modelos.\n",
        "\n",
        "Correlación negativa con churn → los clientes más antiguos tienden a permanecer, mientras que los nuevos cancelan más.\n",
        "\n",
        "MonthlyCharges (Cuota mensual)\n",
        "\n",
        "Fuerte correlación positiva con churn.\n",
        "\n",
        "Los clientes con cargos mensuales más altos son más propensos a cancelar, posiblemente por percepción de costo excesivo.\n",
        "\n",
        "Contract (Tipo de contrato)\n",
        "\n",
        "Contratos de dos años reducen la cancelación drásticamente (seguridad de permanencia).\n",
        "\n",
        "Contratos mensuales tienen mayor riesgo de churn.\n",
        "\n",
        "InternetService (Tipo de servicio de internet)\n",
        "\n",
        "Clientes con fibra óptica presentan más cancelaciones en comparación con DSL o sin internet, posiblemente por problemas de costo/soporte.\n",
        "\n",
        "PaymentMethod (Método de pago)\n",
        "\n",
        "Pagos electrónicos automáticos suelen asociarse con menor churn.\n",
        "\n",
        "Pagos manuales con tarjeta/cheque → mayor churn.\n",
        "\n",
        "TechSupport y OnlineSecurity\n",
        "\n",
        "Los clientes que cuentan con soporte técnico o seguridad online presentan menos cancelaciones.\n",
        "\n",
        "Indican que servicios de valor agregado fidelizan.\n",
        "\n",
        "Dependents (Dependientes en el hogar)\n",
        "\n",
        "Hogares con dependientes cancelan menos (quizás por uso compartido del servicio).\n",
        "\n",
        "SeniorCitizen (Adultos mayores)\n",
        "\n",
        "Se observa un poco más de churn en clientes mayores, aunque no es tan fuerte como otras variables.\n",
        "\n",
        "StreamingTV / StreamingMovies\n",
        "\n",
        "Moderada importancia → clientes que usan streaming pueden estar más comprometidos, pero también sensibles a fallas o precio.\n",
        "\n",
        "✅ Conclusión para el negocio\n",
        "\n",
        "Factores protectores contra el churn: contratos largos, servicios adicionales (soporte técnico, seguridad online), método de pago automático, antigüedad del cliente.\n",
        "\n",
        "Factores de riesgo: altas tarifas mensuales, contratos mensuales, clientes nuevos, uso de fibra óptica sin soporte adecuado.\n",
        "\n",
        "Esto le da a la empresa palancas de acción:\n",
        "\n",
        "Incentivar contratos más largos.\n",
        "\n",
        "Ofrecer descuentos o beneficios a clientes con altas cuotas mensuales.\n",
        "\n",
        "Mejorar soporte técnico y servicios extra.\n",
        "\n",
        "Diseñar campañas específicas para clientes nuevos (primeros 6 meses son críticos)."
      ],
      "metadata": {
        "id": "yecSmEO8W09F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "📌 Código completo con reporte automático\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# ====================================\n",
        "# 1. Ranking por modelo\n",
        "# ====================================\n",
        "rankings = {}\n",
        "\n",
        "# --- Regresión Logística ---\n",
        "coef = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_log.coef_[0]\n",
        "})\n",
        "coef[\"Importancia_Abs\"] = np.abs(coef[\"Importancia\"])\n",
        "coef = coef.sort_values(by=\"Importancia_Abs\", ascending=False)\n",
        "rankings[\"Logística\"] = coef[[\"Variable\", \"Importancia_Abs\"]].rename(columns={\"Importancia_Abs\":\"Importancia\"})\n",
        "\n",
        "# --- KNN (Permutation Importance) ---\n",
        "result_knn = permutation_importance(model_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "imp_knn = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": result_knn.importances_mean\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"KNN\"] = imp_knn\n",
        "\n",
        "# --- Random Forest ---\n",
        "imp_rf = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Importancia\": model_rf.feature_importances_\n",
        "}).sort_values(by=\"Importancia\", ascending=False)\n",
        "rankings[\"Random Forest\"] = imp_rf\n",
        "\n",
        "# --- SVM ---\n",
        "if hasattr(model_svm, \"coef_\"):  # kernel lineal\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": np.abs(model_svm.coef_[0])\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "else:  # kernel no lineal\n",
        "    result_svm = permutation_importance(model_svm, X_test, y_test, n_repeats=10, random_state=42)\n",
        "    imp_svm = pd.DataFrame({\n",
        "        \"Variable\": X.columns,\n",
        "        \"Importancia\": result_svm.importances_mean\n",
        "    }).sort_values(by=\"Importancia\", ascending=False)\n",
        "\n",
        "rankings[\"SVM\"] = imp_svm\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 2. Ranking consolidado\n",
        "# ====================================\n",
        "consolidado = []\n",
        "for modelo, df_rank in rankings.items():\n",
        "    df_norm = df_rank.copy()\n",
        "    df_norm[\"Importancia\"] = df_norm[\"Importancia\"] / df_norm[\"Importancia\"].max()\n",
        "    df_norm[\"Modelo\"] = modelo\n",
        "    consolidado.append(df_norm)\n",
        "\n",
        "consolidado = pd.concat(consolidado)\n",
        "\n",
        "ranking_final = consolidado.groupby(\"Variable\")[\"Importancia\"].mean().sort_values(ascending=False).reset_index()\n",
        "\n",
        "print(\"🔝 Ranking Consolidado de Variables:\")\n",
        "print(ranking_final.head(15))\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 3. Visualización consolidada\n",
        "# ====================================\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=\"Importancia\", y=\"Variable\", data=ranking_final.head(10))\n",
        "plt.title(\"Top 10 Variables - Ranking Consolidado\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# 4. Mini-reporte automático\n",
        "# ====================================\n",
        "top_vars = ranking_final.head(10)[\"Variable\"].tolist()\n",
        "\n",
        "print(\"\\n📋 Reporte Automático de Interpretación:\\n\")\n",
        "\n",
        "for var in top_vars:\n",
        "    if \"tenure\" in var.lower():\n",
        "        print(f\"- {var}: La antigüedad del cliente es clave. Clientes con más tiempo suelen cancelar menos.\")\n",
        "    elif \"monthly\" in var.lower() or \"charge\" in var.lower():\n",
        "        print(f\"- {var}: Los cargos mensuales altos incrementan la probabilidad de cancelación.\")\n",
        "    elif \"contract\" in var.lower():\n",
        "        print(f\"- {var}: El tipo de contrato influye: contratos largos reducen la cancelación, los mensuales aumentan el riesgo.\")\n",
        "    elif \"payment\" in var.lower():\n",
        "        print(f\"- {var}: El método de pago es relevante. Pagos automáticos suelen asociarse con menos churn.\")\n",
        "    elif \"internet\" in var.lower():\n",
        "        print(f\"- {var}: El tipo de servicio de internet impacta. Fibra óptica suele tener más cancelación que DSL.\")\n",
        "    elif \"support\" in var.lower() or \"security\" in var.lower():\n",
        "        print(f\"- {var}: Servicios adicionales como soporte técnico o seguridad online reducen el churn.\")\n",
        "    elif \"senior\" in var.lower():\n",
        "        print(f\"- {var}: Los clientes mayores tienden a cancelar un poco más que otros segmentos.\")\n",
        "    elif \"depend\" in var.lower():\n",
        "        print(f\"- {var}: Los clientes con dependientes en el hogar suelen permanecer más tiempo.\")\n",
        "    elif \"stream\" in var.lower():\n",
        "        print(f\"- {var}: El uso de streaming puede fidelizar, pero también aumenta la sensibilidad a precio y calidad.\")\n",
        "    else:\n",
        "        print(f\"- {var}: Variable relevante detectada, merece un análisis más detallado en el negocio.\")\n",
        "\n",
        "📊 Qué hace este código\n",
        "\n",
        "Genera ranking de importancia por cada modelo.\n",
        "\n",
        "Construye un ranking consolidado (promedio normalizado entre modelos).\n",
        "\n",
        "Muestra un gráfico del Top 10 consolidado.\n",
        "\n",
        "Produce un mini-reporte interpretado automáticamente, con explicaciones sobre las variables más importantes (tenure, charges, contract, etc.)."
      ],
      "metadata": {
        "id": "BleRPSOrW2oX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}